# -*- coding: utf-8 -*-
"""redux_processONLYONEFILE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cCGAt4sflEu_bhreWKxvh3xnQ7LPkGsN
"""

from music21 import *
from collections import Counter
import numpy as np
import pandas as pd
from scipy import spatial
import matplotlib.pyplot as plt
import glob

# The full TIV library isn't importing correctly to the program, so here is a part of the TIV library.
class TIV:
    weights_symbolic = [2, 11, 17, 16, 19, 7]
    weights_audio = [3, 8, 11.5, 15, 14.5, 7.5]

    def __init__(self, energy, vector):
        self.energy = energy
        self.vector = vector

    def abs_vector(self):
        return np.abs(self.vector)

    def phases_vector(self):
        return np.angle(self.vector)

    def get_vector(self):
        return np.array(self.vector)

    def diss(self):  # Compute dissonance
        return 1 - (np.linalg.norm(self.vector) / np.sqrt(np.sum(np.dot(self.weights_symbolic, self.weights_symbolic))))

    def coeffs(self, coef):  # Compute coefficient
        return self.abs_vector()[coef] / self.weights_symbolic[coef]

    def chromaticity(self):  # Compute chromaticity
        return self.abs_vector()[0] / self.weights_symbolic[0]

    def dyads(self):  # Compute dyadicity
        return self.abs_vector()[1] / self.weights_symbolic[1]

    def triads(self):  # Compute triadicity (triads)
        return self.abs_vector()[2] / self.weights_symbolic[2]

    def d_q(self):  # Refers a possible diminished quality
        return self.abs_vector()[3] / self.weights_symbolic[3]

    def diatonal(self):  # Compute diatonicity
        return self.abs_vector()[4] / self.weights_symbolic[4]

    def tone(self):  # Define wholetoneness
        return self.abs_vector()[5] / self.weights_symbolic[5]

    @classmethod
    def from_pcp(cls, pcp, symbolic=True):
        #      Get TIVs from pcp, as the original method
        #     :param pcp: 12xN vector containing N pcps
        #     :return: TIVCollection object
        #     """
        if pcp.shape[0] == 12:
            fft = np.fft.rfft(pcp, n=12)
            energy = fft[0]
            vector = fft[1:7]
            if symbolic:
                vector = ((vector / energy) * cls.weights_symbolic)
            else:
                vector = ((vector / energy) * cls.weights_audio)
            return cls(energy, vector)
        else:
            return cls(complex(0), np.array([0, 0, 0, 0, 0, 0]).astype(complex))

    def plot_TIV(self):
        titles = ["m2/M7", "TT", "M3/m6", "m3/M6", "P4/P5", "M2/m7"]
        TIVector = self.vector / self.weights_symbolic
        i = 1
        for tiv in TIVector:
            circle = plt.Circle((0, 0), 1, fill=False)
            plt.subplot(2, 3, i)
            plt.subplots_adjust(hspace=0.4)
            plt.gca().add_patch(circle)
            plt.title(titles[i - 1])
            plt.scatter(tiv.real, tiv.imag)
            plt.xlim((-1.5, 1.5))
            plt.ylim((-1.5, 1.5))
            plt.grid()
            i = i + 1
        plt.show()

    def hchange(self):
        tiv_array = self.vector
        results = []
        for i in range(len(tiv_array)):
            distance = TIV.euclidean(tiv_array[i + 1], tiv_array[i])
            results.append(distance)
        return results

#Just to order list of TIV_Redux
def sort_dist(dist):
    return dist[1]

def dist_calc(pitches_chord, dist):
    dist_list = []
    hist = Counter(pitches_chord)
    pitch_list = [0] * 12
    for pitch in hist:
        index = pitch % 12
        pitch_list[index] += hist[pitch]
    TIV_vector = TIV.from_pcp(np.array(pitch_list))

    for i in range(len(pitches_chord)):
        each_pitch = pitches_chord[i]
        aux_vector = [0] * 12
        aux_vector[each_pitch % 12] += 1
        aux_vector = TIV.from_pcp(np.array(aux_vector))
        distance = dist(TIV_vector.vector, aux_vector.vector)
        dist_list.append((i, distance))
    return dist_list

#The aim is to only show the notes that are going to be cut by the reduction step
#(Taking into account that the representation of each chord are only up to 3 notes maximum)
def TIV_Redux(pitches_chord, dist):
    dist_list = dist_calc(pitches_chord, dist)
    dist_list.sort(key=sort_dist)
    dist_reduced = dist_list[3:] #only show the notes that are going to be cut, reducing the chord
    return dist_reduced

b = corpus.parse('bwv66.6')
bChords = b.chordify()
bChords.show()

def info_chord(stream):
  midi_pitches = []
  duration_pitches = []
  offset_pitches = []

  for chord in stream.flatten().getElementsByClass('Chord'):
    midi_pitches.append([n.pitch.midi for n in chord.notes])
    duration_pitches.append([n.quarterLength for n in chord.notes])
    offset_pitches.append([chord.offset for n in chord])
  
  print(midi_pitches)
  print(duration_pitches)
  print(offset_pitches)
  return midi_pitches, duration_pitches, offset_pitches

m, d, o = info_chord(bChords)

def red_notes_quantifier(list):
  reduced_notes_lst = []
  for s in m:
    red_notes = TIV_Redux(s, spatial.distance.euclidean)
    e = [x[0] for x in red_notes]
    n_name = [note.Note(s[i]).nameWithOctave for i in e]
    if n_name:
        reduced_notes_lst.append(n_name)
  return reduced_notes_lst

red_notes_lst = red_notes_quantifier(m)

def times_info(offset_pitches):
  times_offset = []
  for value in offset_pitches:
     if len(value) >= 4:
         times_offset.append(value[0])
  #times_offset.sort()
  #print(times_offset)
  return times_offset

t = times_info(o)
print(t)

def stream_painted_notes(stream1 ,notes_lst, times_offset):
  final_reduced_list = zip(notes_lst, times_offset)
  zipped_reduced_list = list(final_reduced_list)
  zipped_reduced_list.sort(key=lambda x: x[1])
  #print(zipped_reduced_list)

  for i in range(len(zipped_reduced_list)):
    for j in range(len(zipped_reduced_list[i][0])):
      if len(zipped_reduced_list[i][0]) > 0:
        note_zipped = note.Note(zipped_reduced_list[i][0][j])
        note_zipped.style.color = 'red'
        stream1.insert(zipped_reduced_list[i][1], note_zipped)

  stream1 = stream1.flat
  return stream1

bChords_PAINTED_NOTES = stream_painted_notes(bChords,red_notes_lst, t)
bChords_PAINTED_NOTES.show()

def reduced_stream(stream):
  chord_pitches = []
  for chord in stream.flatten().getElementsByClass('Chord'):
    chord_new = chord
    n = [n.pitch.midi for n in chord_new.notes]
    n_pitch = [nt for nt in chord_new.pitches] #All pitches from each chord
    red_chord = TIV_Redux(n, spatial.distance.euclidean) #Putting TIV on the equation
    e = [x[0] for x in red_chord]
    n_to_cut = [n_pitch[i] for i in e] #The pitches of notes that are going to be cutted from the chord
    for element in n_to_cut:
      if element in n_pitch:
        #n.remove(element)
        for i in chord_new.pitches:
          if i == element:
            chord_new.remove(i)
  stream.replace(chord,chord_new)
  return stream

bChords_REDUCED_SCORE = reduced_stream(bChords)
bChords_REDUCED_SCORE.show()

"""#NOW WITHOUT DUPLICATED NOTES ON THE CHORD:

"""

#Initialize once again to promote a new part of the resolution
b = corpus.parse('bwv66.6')
bChords = b.chordify()
bChords.show()

def non_duplicated_stream(stream):
  for chord in stream.flatten().getElementsByClass('Chord'):
    chord = chord.removeRedundantPitchNames(inPlace=True)
  return stream

bChords_NonDuplicated = non_duplicated_stream(bChords)
bChords_NonDuplicated.show()

m_NonDuplicated, d_NonDuplicated, o_NonDuplicated = info_chord(bChords_NonDuplicated)
reduced_notes_lst_NonDuplicated = red_notes_quantifier(m_NonDuplicated)
t_nonDuplicated = times_info(o_NonDuplicated)
NonDuplicatedStream_PAINTED_NOTES = stream_painted_notes(bChords_NonDuplicated,reduced_notes_lst_NonDuplicated, t_nonDuplicated)
NonDuplicatedStream_PAINTED_NOTES.show()

NonDuplicatedStream_REDUCED_NOTES = reduced_stream(bChords_NonDuplicated)
NonDuplicatedStream_REDUCED_NOTES.show()